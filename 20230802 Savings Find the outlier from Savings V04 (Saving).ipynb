{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64b7cafe",
   "metadata": {},
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bbda6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import openpyxl\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Plotly Tools\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as offline\n",
    "offline.init_notebook_mode()\n",
    "from plotly import tools\n",
    "import plotly.tools as tls\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "\n",
    "import cufflinks as cf\n",
    "cf.go_offline()\n",
    "cf.set_config_file(offline=False, world_readable=True)\n",
    "\n",
    "\n",
    "# Max column\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706b21a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Location of file\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac4eb53",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4060b4a",
   "metadata": {},
   "source": [
    "* List of purchaser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a75aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ID file location\n",
    "ID_file = pd.read_excel(\"D:/Shaikh_Desktop_Mydoc/Desktop/Automation Projects/20230727_Savings_Report_Commercial/Data/ID2.xlsx\")\n",
    "\n",
    "# Extract the IDs from the ID file\n",
    "IDs = ID_file['Name']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3c9771",
   "metadata": {},
   "source": [
    "* Monthly data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3612e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"D:/Shaikh_Desktop_Mydoc/Desktop/Automation Projects/20230727_Savings_Report_Commercial/Data/August_23.xls\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8d14cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data types for specific columns\n",
    "data_types = {\n",
    "    'Order Date': 'datetime64',\n",
    "    'Item Code': str,\n",
    "    'POReference': str,\n",
    "    'Supplier Id': str\n",
    "}\n",
    "\n",
    "# Load the data from Excel file, skipping the first 5 rows, and applying data types\n",
    "MonthlyData = pd.read_excel(file_path, skiprows=range(0, 5), dtype=data_types)\n",
    "\n",
    "# Print the DataFrame\n",
    "display(MonthlyData.head(5))\n",
    "display(MonthlyData.info())\n",
    "display(MonthlyData.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422cabc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "MonthlyData.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1947daf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the columns you want to keep from the other file\n",
    "columns_to_keep = ['Unnamed: 0', 'Business', 'Unnamed: 2', 'Supplier Id', 'Supplier Name',\n",
    "       'Unnamed: 5', 'Unnamed: 6', 'Country', 'Unnamed: 8', 'Currency',\n",
    "       'POReference', 'Unnamed: 11', 'Order Date', 'Order Type', 'Category',\n",
    "       'Item Code', 'Item Name', 'Unit', 'POQuantity', 'PORate', 'Amount',\n",
    "       'Advance', 'Create By', 'Create Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b08c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the other file based on the IDs and select the desired columns\n",
    "MonthlyData_Commercial_only = MonthlyData[MonthlyData['Create By'].isin(IDs)][columns_to_keep]\n",
    "\n",
    "MonthlyData_Commercial_only\n",
    "display(MonthlyData_Commercial_only.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36382617",
   "metadata": {},
   "outputs": [],
   "source": [
    "MonthlyData['Business'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdb8341",
   "metadata": {},
   "source": [
    "## Data cleaning and Data manipulation\n",
    "\n",
    "<p> Remove Order type 'Biz Promo', 'Contract Order' </p>\n",
    "<p> Remove Business ACI CO-RO </p>\n",
    "<p> <mark> Remove row if Category contains PI </mark> </p>\n",
    "<p> <mark> Remove 'FG' and 'RM' from Electrical </mark> </p>\n",
    "<p> Remove Colgate, Cevac, Freight, Colgate </p>\n",
    "<p> Remove Import items from 'Vegetables', 'Field Crops', 'Vegetables-EWS'</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dce140e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##________________________________ the values to remove________________________________\n",
    "\n",
    "values_to_remove_ordertype = ['Biz Promo', 'Contract Order']\n",
    "values_to_remove_business = ['ACI CO-RO']\n",
    "values_to_remove_Category = ['PI']\n",
    "\n",
    "# Filter the DataFrame to remove rows where \"Order Type\" column contains specific values\n",
    "df = MonthlyData_Commercial_only[~MonthlyData_Commercial_only['Order Type'].isin(values_to_remove_ordertype)]\n",
    "df = df[~df['Business'].isin(values_to_remove_ordertype)]\n",
    "df = df[~df['Item Name'].str.contains('Colgate', case=False)]\n",
    "df = df[~df['Item Name'].str.contains('Cevac', case=False)]\n",
    "df = df[~df['Item Name'].str.contains('Freight', case=False)]\n",
    "df = df[~df['Supplier Name'].str.contains('Colgate', case=False)]\n",
    "df = df[~df['Category'].isin(values_to_remove_Category)]\n",
    "\n",
    "\n",
    "\n",
    "# ### Define the conditions for removing rows\n",
    "# business_to_exclude = ['Electrical']\n",
    "# category_to_exclude = ['FG', 'RM']\n",
    "\n",
    "# # Filter rows based on the specified conditions\n",
    "# df = df[~((df['Business'].isin(business_to_exclude)) & (df['Category'].isin(category_to_exclude)))]\n",
    "\n",
    "\n",
    "### Define the conditions for removing rows\n",
    "business_to_exclude2 = ['Vegetables', 'Field Crops', 'Vegetables-EWS']\n",
    "category_to_exclude2 = ['Import']\n",
    "\n",
    "# Filter rows based on the specified conditions\n",
    "df = df[~((df['Business'].isin(business_to_exclude2)) & (df['Order Type'].isin(category_to_exclude2)))]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##________________________________ the values to rename________________________________\n",
    "\n",
    "df.loc[(df['Order Type'] == 'Import') & (df['Currency'] == 'BDT'), 'Order Type'] = 'Native'    # Local LC to Local\n",
    "df['Order Type'] = df['Order Type'].apply(lambda x: x.replace('Native', 'Local'))              # Native to Local\n",
    "\n",
    "\n",
    "display(df.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Note\n",
    "#The ~ operator negates the condition, so it selects rows where the "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128d740c",
   "metadata": {},
   "source": [
    "\n",
    "* Outlier detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cb236b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Local_Non_BDT1 = df.loc[(df['Order Type'] == 'Local') & (df['Currency'] != 'BDT')]\n",
    "Local_Non_BDT2 = df.loc[(df['Order Type'] == 'Native')]\n",
    "Import_BDT = df.loc[(df['Order Type'] == 'Import') & (df['Currency'] == 'BDT')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5740a5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_rows = df[df.duplicated(subset=['Currency','Item Code', 'POQuantity'], keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482554cc",
   "metadata": {},
   "source": [
    "### Import Data from Another DataBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c1cf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File Path for WAP\n",
    "\n",
    "File_WAP = \"D:/Shaikh_Desktop_Mydoc/Desktop/Automation Projects/20230727_Savings_Report_Commercial/Output_file/Lastprice_WAP_AVRate.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d1d420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of Sheets in WAP file\n",
    "\n",
    "# Load the Excel file using openpyxl\n",
    "workbook = openpyxl.load_workbook(File_WAP)\n",
    "\n",
    "# Get the list of sheet names\n",
    "sheet_names = workbook.sheetnames\n",
    "\n",
    "# Print the list of sheet names\n",
    "display(sheet_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452bfdd4",
   "metadata": {},
   "source": [
    "* Average Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67981b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the sheet name from which you want to load data\n",
    "AVRate_fy_22_23 = \"AV_Rate\" \n",
    "\n",
    "# Load data from the specified sheet\n",
    "AVRate_ = pd.read_excel(File_WAP, sheet_name= AVRate_fy_22_23)\n",
    "\n",
    "display(AVRate_.columns)\n",
    "display(AVRate_.head(5))\n",
    "display(AVRate_.shape)\n",
    "\n",
    "\n",
    "# AVRate_.rename(columns={'PORate': 'AVRate'}, inplace=True)\n",
    "\n",
    "\n",
    "display(AVRate_.columns)\n",
    "display(AVRate_.head(5))\n",
    "display(AVRate_.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df = pd.merge(df, AVRate_, on=['Business', 'Item Code', 'Currency'], how='left')\n",
    "display(df.head(5))\n",
    "display(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f928b781",
   "metadata": {},
   "source": [
    "* WAP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088a92e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the sheet name from which you want to load data\n",
    "WAP_fy_22_23 = \"WAP\" \n",
    "\n",
    "# Load data from the specified sheet\n",
    "WAP_ = pd.read_excel(File_WAP, sheet_name=WAP_fy_22_23)\n",
    "\n",
    "display(WAP_.columns)\n",
    "display(WAP_.head(5))\n",
    "display(WAP_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f2d102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# left outer join\n",
    "\n",
    "\n",
    "df_report = pd.merge(df, WAP_, on=['Business', 'Item Code', 'Currency'], how='left')\n",
    "display(df_report.head(5))\n",
    "display(df_report.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec36546",
   "metadata": {},
   "source": [
    "* WAP: 6 Months "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21a448c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the sheet name from which you want to load data\n",
    "WAP_6M = \"6M_WAP\" \n",
    "\n",
    "# Load data from the specified sheet\n",
    "WAP_6M_ = pd.read_excel(File_WAP, sheet_name=WAP_6M)\n",
    "\n",
    "display(WAP_6M_.columns)\n",
    "display(WAP_6M_.head(5))\n",
    "display(WAP_6M_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c66207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# left outer join\n",
    "\n",
    "\n",
    "df_report = pd.merge(df_report, WAP_6M_, on=['Business', 'Item Code', 'Currency'], how='left')\n",
    "display(df_report.head(5))\n",
    "display(df_report.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c65072c",
   "metadata": {},
   "source": [
    "* June or previous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f14637",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Specify the sheet name from which you want to load data\n",
    "July_or_previous = \"July23\" \n",
    "\n",
    "# Load data from the specified sheet\n",
    "July__ = pd.read_excel(File_WAP, sheet_name=July_or_previous)\n",
    "\n",
    "display(July__.columns)\n",
    "display(July__.head(5))\n",
    "display(July__.shape)\n",
    "\n",
    "\n",
    "\n",
    "# Columns for June or previous \n",
    "\n",
    "columns_to_keep_June = ['Business','Currency','Item Code', 'PORate']\n",
    "July__ = July__[columns_to_keep_June]\n",
    "\n",
    "July__.rename(columns={'PORate': 'June or Previous price'}, inplace=True)\n",
    "\n",
    "July__.columns\n",
    "display(July__.head(5))\n",
    "display(July__.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a8cf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# left outer join\n",
    "\n",
    "\n",
    "df_report = pd.merge(df_report, July__, on=['Business', 'Item Code', 'Currency'], how='left')\n",
    "display(df_report.head(5))\n",
    "display(df_report.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc240e46",
   "metadata": {},
   "source": [
    "* Last Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9803b0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_types = {\n",
    "    'Order Date': 'datetime64',\n",
    "    'Item Code': str,\n",
    "    'POReference': str,\n",
    "    'Supplier Id': str\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Specify the sheet name from which you want to load data\n",
    "Last_Price = \"Lastprice\" \n",
    "\n",
    "# Load data from the specified sheet\n",
    "Last_Price_ = pd.read_excel(File_WAP, sheet_name= Last_Price, dtype = data_types)\n",
    "\n",
    "display(Last_Price_.columns)\n",
    "display(Last_Price_.head(5))\n",
    "display(Last_Price_.shape)\n",
    "\n",
    "\n",
    "\n",
    "# Columns for June or previous \n",
    "\n",
    "columns_to_keep_LP = ['Business','Currency','POReference','Item Code', 'Last_Price']\n",
    "Last_Price__ = Last_Price_[columns_to_keep_LP]\n",
    "\n",
    "# Last_Price__.rename(columns={'PORate': 'LastPrice'}, inplace=True)\n",
    "\n",
    "Last_Price__.columns\n",
    "display(Last_Price__.head(5))\n",
    "display(Last_Price__.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da888c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# left outer join\n",
    "\n",
    "\n",
    "df_report = pd.merge(df_report, Last_Price__, on=['POReference', 'Business', 'Item Code', 'Currency'], how='left')\n",
    "display(df_report.head(5))\n",
    "display(df_report.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adba53f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report_ = df_report.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e813d83",
   "metadata": {},
   "source": [
    "### Analytics : 001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6632750e",
   "metadata": {},
   "source": [
    "* Calculate variance (WAP vs Average Rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3995bc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Analytics = df_report.copy()\n",
    "display(df_Analytics.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c74c566",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "columns_to_keep_Analytics = ['Business', 'Supplier Id', 'Supplier Name','Country', 'Currency','POReference', 'Order Date', 'Order Type', 'Category',\n",
    "'Item Code', 'Item Name', 'Unit', 'POQuantity', 'PORate', 'Amount','Advance', 'Create By', 'Create Date', 'AVRate', 'WAP',\n",
    "       'June or Previous price', 'Last_Price']\n",
    "df_Analytics = df_Analytics[columns_to_keep_Analytics]\n",
    "\n",
    "display(df_Analytics.head(5))\n",
    "display(df_Analytics.shape)\n",
    "display(df_Analytics.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ca9fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the variance between AVRate and WAP\n",
    "df_Analytics['Difference'] = (df_Analytics['AVRate'] - df_Analytics['WAP'])\n",
    "df_Analytics['Variance_P'] = ((df_Analytics['AVRate'] - df_Analytics['WAP'])/df_Analytics['AVRate'])*100\n",
    "\n",
    "# Create a separate DataFrame for high variance cases\n",
    "high_variance_df = df_Analytics[df_Analytics['Variance_P'].abs() >5]\n",
    "\n",
    "# Print the DataFrames\n",
    "display(\"Original DataFrame:\")\n",
    "display(df_Analytics.head())\n",
    "display(\"\\nHigh Variance DataFrame:\")\n",
    "display(high_variance_df.head())\n",
    "display(high_variance_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b6594a",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(high_variance_df.head(5))\n",
    "display(high_variance_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29c2128",
   "metadata": {},
   "source": [
    "### Load data: From historical DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976c5285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder path containing the files\n",
    "pathSpecified = \"D:/Shaikh_Desktop_Mydoc/Desktop/Automation Projects/20220622 PriceMirror/MMS2018JanTo2023Jun\"  # Replace with the actual folder path\n",
    "\n",
    "# Using listdir() function  \n",
    "listOfFileNames = os.listdir(pathSpecified)\n",
    "\n",
    "\n",
    "# Print the name of all files in directory  \n",
    "print(\"Following is the list of names of all the files present in the specified directory: \")  \n",
    "# Create an empty DataFrame to store the combined data\n",
    "combined_data = pd.DataFrame()\n",
    "print(listOfFileNames)\n",
    "\n",
    "\n",
    "\n",
    "# Create an empty DataFrame to store the combined data\n",
    "combined_data = pd.DataFrame()\n",
    "\n",
    "\n",
    "# Iterate over the file names\n",
    "for file_name in listOfFileNames:\n",
    "    # Construct the file path\n",
    "    file_path = os.path.join(pathSpecified, file_name)\n",
    "    # Read the file into a DataFrame\n",
    "    # Define the skiprows and column data types\n",
    "    skiprows = 5\n",
    "    dtype = {\n",
    "        'Order Date': 'datetime64',\n",
    "        'Item Code': str,\n",
    "        'POReference': str,\n",
    "        'Supplier Id' : str,\n",
    "        \n",
    "        \n",
    "    }\n",
    "\n",
    "    # Load the Excel file\n",
    "    data = pd.read_excel(file_path, index_col=False, skiprows=range(0, 5), dtype=dtype).iloc[0:].reset_index(drop=True)\n",
    "    combined_data = combined_data.append(data)\n",
    "# Display the loaded data\n",
    "combined_data.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baab4da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# business_to_keep = ['ACI Animal Genetics',\n",
    "# 'ACI Consumer Electronics',\n",
    "# 'ACI Crop Care (ACI Formulations Limited)',\n",
    "# 'ACI Flour',\n",
    "# 'ACI Foods Ltd.',\n",
    "# 'ACI Premio Plastics',\n",
    "# 'Aerosol',\n",
    "# 'Animal Health',\n",
    "# 'CB Core ', \n",
    "# 'Edible Oil',\n",
    "# 'Fertilizer',\n",
    "# 'Hygiene',\n",
    "# 'Paint',\n",
    "# 'Pharma',\n",
    "# 'Premiaflex',\n",
    "# 'ACI Salt',\n",
    "# 'Electrical',\n",
    "# 'Field Crops',\n",
    "# 'Mosquito Coil',\n",
    "# 'Rice',\n",
    "# 'Vanish',\n",
    "# 'Vegetables',\n",
    "# 'Vegetables-EWS',\n",
    "# ]\n",
    "\n",
    "# # business_to_keep =['Hygiene']\n",
    "\n",
    "\n",
    "# combined_data = combined_data[combined_data['Business'].isin(business_to_keep)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6dd5a7",
   "metadata": {},
   "source": [
    "### Analytics :002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198e6394",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data['Year'] = combined_data['Order Date'].dt.year\n",
    "combined_data['Month'] = combined_data['Order Date'].dt.month_name()\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_wap(amount, quantity):\n",
    "    if quantity != 0:\n",
    "        wap = amount / quantity\n",
    "        return wap\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Group by 'Item Code', 'Year', and 'Month', and calculate the WAP\n",
    "grouped_data = combined_data.groupby(['Order Type','Business','Item Code','Currency', 'Year', 'Month']).apply(lambda x: calculate_wap(x['Amount'].sum(), x['POQuantity'].sum()))\n",
    "\n",
    "# Reset the index and rename the column\n",
    "grouped_data = grouped_data.reset_index().rename(columns={0: 'WAP_MOM'})\n",
    "\n",
    "grouped_data['Day'] = 1\n",
    "\n",
    "\n",
    "\n",
    "# Generate automatic column names\n",
    "column_names = grouped_data['Year'].astype(str) + '-' + grouped_data['Month'].astype(str) + '-' + grouped_data['Day'].astype(str)\n",
    "\n",
    "pivot_df = grouped_data.pivot_table(index=['Business', 'Item Code','Currency'], columns=column_names, values='WAP_MOM', aggfunc=lambda x: x).reset_index()\n",
    "\n",
    "\n",
    "# Define the desired column order\n",
    "desired_order = ['Business', 'Item Code', 'Currency']\n",
    "\n",
    "# Extract date columns and sort them in chronological order\n",
    "date_columns = sorted([col for col in pivot_df.columns if '-' in col], key=lambda x: pd.to_datetime(x, format='%Y-%B-%d'))\n",
    "\n",
    "# Concatenate the desired order with the sorted date columns\n",
    "desired_order += date_columns\n",
    "\n",
    "# Reindex the DataFrame columns\n",
    "pivot_df = pivot_df.reindex(columns=desired_order)\n",
    "\n",
    "display(pivot_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb6be61",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7e1134",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep_for_wap = ['Business', 'Item Code', 'Currency', '2022-January-1', '2022-February-1', '2022-March-1', '2022-April-1',\n",
    "       '2022-May-1', '2022-June-1', '2022-July-1', '2022-August-1',\n",
    "       '2022-September-1', '2022-October-1', '2022-November-1',\n",
    "       '2022-December-1', '2023-January-1', '2023-February-1', '2023-March-1',\n",
    "       '2023-April-1', '2023-May-1', '2023-June-1', '2023-July-1']\n",
    "\n",
    "pivot_df_wap = pivot_df[columns_to_keep_for_wap]\n",
    "\n",
    "pivot_df_wap.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2076abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# left outer join\n",
    "\n",
    "\n",
    "high_variance_df_ANA2 = pd.merge(high_variance_df, pivot_df_wap, on=['Business', 'Item Code', 'Currency'], how='left')\n",
    "display(high_variance_df_ANA2.head(5))\n",
    "display(high_variance_df_ANA2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17de3604",
   "metadata": {},
   "source": [
    "### Make Business group "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032e3575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to map business values\n",
    "def map_business(business):\n",
    "    if business in ['ACI Flour', 'ACI Foods Ltd.', 'ACI Salt', 'Edible Oil']:\n",
    "        return 'Foods,Flour,Salt& Edible Oils'\n",
    "    elif business == 'ACI Consumer Electronics':\n",
    "        return 'ACI Consumer Electronics'\n",
    "    elif business == 'ACI Crop Care (ACI Formulations Limited)':\n",
    "        return 'ACI Crop Care'\n",
    "    elif business == 'ACI Premio Plastics':\n",
    "        return 'ACI Premio Plastics'\n",
    "    elif business == 'Animal Health':\n",
    "        return 'Animal Health'\n",
    "    elif business == 'CB Core ':\n",
    "        return 'Consumer'\n",
    "    elif business == 'Pharma':\n",
    "        return 'Consumer'\n",
    "    elif business == 'Electrical':\n",
    "        return 'Electrical'\n",
    "    elif business in ['Fertilizer', 'Field Crops', 'Vegetables', 'Vegetables-EWS']:\n",
    "        return 'Fertilizer'\n",
    "    elif business == 'Hygiene':\n",
    "        return 'Hygiene'\n",
    "    elif business == 'Paint':\n",
    "        return 'Paint'\n",
    "    elif business == 'ACI Animal Genetics':\n",
    "        return 'ACI Animal Genetics'\n",
    "    elif business == 'Premiaflex':\n",
    "        return 'Premiaflex'\n",
    "    elif business == 'Rice':\n",
    "        return 'Rice'\n",
    "    elif business in ['Aerosol', 'Vanish', 'Mortin']:\n",
    "        return 'SCJ'\n",
    "    else:\n",
    "        return \"Other\"\n",
    "\n",
    "# Apply the mapping function to the 'Business' column\n",
    "df_report_['Business Name'] = df_report_['Business'].apply(map_business)\n",
    "\n",
    "display(df_report_.head())\n",
    "display(df_report_.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb963998",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df_report_.groupby(['Business', 'Business Name'])['Amount'].sum().reset_index()\n",
    "display(grouped.sort_values(by='Business Name'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03ab8cc",
   "metadata": {},
   "source": [
    "### Procurement & Savings Claculation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df53df8",
   "metadata": {},
   "source": [
    "* Conversion rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5c05a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_report_[\"Currency\"].unique())\n",
    "\n",
    "Value_of_USD = 110\n",
    "Value_of_EUR = 120\n",
    "Value_of_GBP = 135\n",
    "Value_of_BDT = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45980d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Total_ampunt_cal (row):\n",
    "    if row['Currency']=='USD': \n",
    "        return row['POQuantity']* row['PORate']*Value_of_USD\n",
    "    elif row['Currency']=='EUR': \n",
    "        return row['POQuantity']* row['PORate']*Value_of_EUR\n",
    "    elif row['Currency']=='GBP': \n",
    "        return row['POQuantity']* row['PORate']*Value_of_GBP\n",
    "    elif row['Currency']=='BDT': \n",
    "        return row['POQuantity']* row['PORate']*Value_of_BDT\n",
    "    else:\n",
    "        return \"No Currency Match\"\n",
    "\n",
    "\n",
    "\n",
    "def Savings_Jun_cal (row):\n",
    "    if row['Currency']=='USD': \n",
    "        return row['POQuantity']*(row['June or Previous price'] - row['PORate'])*Value_of_USD\n",
    "    elif row['Currency']=='EUR': \n",
    "        return row['POQuantity']* (row['June or Previous price'] - row['PORate'])*Value_of_EUR\n",
    "    elif row['Currency']=='GBP': \n",
    "        return row['POQuantity']* (row['June or Previous price'] - row['PORate'])*Value_of_GBP\n",
    "    elif row['Currency']=='BDT': \n",
    "        return row['POQuantity']* (row['June or Previous price'] - row['PORate'])*Value_of_BDT\n",
    "    else:\n",
    "        return \"No Currency Match\"\n",
    "\n",
    "\n",
    "def Savings_WAP_cal (row):\n",
    "    if row['Currency']=='USD': \n",
    "        return row['POQuantity']*(row['WAP'] - row['PORate'])*Value_of_USD\n",
    "    elif row['Currency']=='EUR': \n",
    "        return row['POQuantity']* (row['WAP'] - row['PORate'])*Value_of_EUR\n",
    "    elif row['Currency']=='GBP': \n",
    "        return row['POQuantity']* (row['WAP'] - row['PORate'])*Value_of_GBP\n",
    "    elif row['Currency']=='BDT': \n",
    "        return row['POQuantity']* (row['WAP'] - row['PORate'])*Value_of_BDT\n",
    "    else:\n",
    "        return \"No Currency Match\"\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def Savings_WAP_6M_cal (row):\n",
    "    if row['Currency']=='USD': \n",
    "        return row['POQuantity']*(row['Last_Price'] - row['PORate'])*Value_of_USD\n",
    "    elif row['Currency']=='EUR': \n",
    "        return row['POQuantity']* (row['Last_Price'] - row['PORate'])*Value_of_EUR\n",
    "    elif row['Currency']=='GBP': \n",
    "        return row['POQuantity']* (row['Last_Price'] - row['PORate'])*Value_of_GBP\n",
    "    elif row['Currency']=='BDT': \n",
    "        return row['POQuantity']* (row['Last_Price'] - row['PORate'])*Value_of_BDT\n",
    "    else:\n",
    "        return \"No Currency Match\"\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def Savings_LastPrice_cal (row):\n",
    "    if row['Currency']=='USD': \n",
    "        return row['POQuantity']*(row['WAP_6M'] - row['PORate'])*Value_of_USD\n",
    "    elif row['Currency']=='EUR': \n",
    "        return row['POQuantity']* (row['WAP_6M'] - row['PORate'])*Value_of_EUR\n",
    "    elif row['Currency']=='GBP': \n",
    "        return row['POQuantity']* (row['WAP_6M'] - row['PORate'])*Value_of_GBP\n",
    "    elif row['Currency']=='BDT': \n",
    "        return row['POQuantity']* (row['WAP_6M'] - row['PORate'])*Value_of_BDT\n",
    "    else:\n",
    "        return \"No Currency Match\"\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "df_report_[\"Total_Value_in_Taka\"] = df_report_.apply(Total_ampunt_cal, axis=1)\n",
    "df_report_[\"Savings_June\"] = df_report_.apply(Savings_Jun_cal, axis=1)\n",
    "df_report_[\"Savings_WAP\"] = df_report_.apply(Savings_WAP_cal, axis=1)\n",
    "df_report_[\"Savings_WAP_6M\"] = df_report_.apply(Savings_WAP_6M_cal, axis=1)\n",
    "df_report_[\"Savings_LastPrice\"] = df_report_.apply(Savings_LastPrice_cal, axis=1)\n",
    "\n",
    "display(df_report_.head())\n",
    "display(df_report_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ddeec5",
   "metadata": {},
   "source": [
    "### Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85e9bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by \"Business Name\" and \"Local/Import,\" then apply aggregation\n",
    "Final_report = df_report_.groupby(['Business Name', 'Order Type']).agg(Total_Value_in_Taka=('Total_Value_in_Taka', 'sum'),\n",
    "    Savings_June=('Savings_June', 'sum'),\n",
    "    Savings_WAP=('Savings_WAP', 'sum'),\n",
    "    Savings_LastPrice=('Savings_LastPrice', 'sum'),\n",
    "    Savings_WAP_6M=('Savings_WAP_6M', 'sum')).reset_index()\n",
    "\n",
    "# Display the grouped report\n",
    "display(Final_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d0d516",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_gain_loss(dataframe, column_name):\n",
    "    gain_column = \"Gain_\" + column_name\n",
    "    loss_column = \"Loss_\" + column_name\n",
    "    \n",
    "    gain_df = dataframe[dataframe[column_name] >= 0]\n",
    "    loss_df = dataframe[dataframe[column_name] < 0]\n",
    "    \n",
    "    return gain_df, loss_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11a3922",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Call the function for each column\n",
    "gain_june_df, loss_june_df = separate_gain_loss(Final_report, 'Savings_June')\n",
    "gain_wap_df, loss_wap_df = separate_gain_loss(Final_report, 'Savings_WAP')\n",
    "gain_wap_6m_df, loss_wap_6m_df = separate_gain_loss(Final_report, 'Savings_WAP_6M')\n",
    "\n",
    "# Display the Gain and Loss dataframes for each column\n",
    "print(\"Gain Data for Savings_June:\")\n",
    "display(gain_june_df)\n",
    "\n",
    "print(\"\\nLoss Data for Savings_June:\")\n",
    "display(loss_june_df)\n",
    "\n",
    "print(\"\\nGain Data for Savings_WAP:\")\n",
    "display(gain_wap_df)\n",
    "\n",
    "print(\"\\nLoss Data for Savings_WAP:\")\n",
    "display(loss_wap_df)\n",
    "\n",
    "print(\"\\nGain Data for Savings_WAP_6M:\")\n",
    "display(gain_wap_6m_df)\n",
    "\n",
    "print(\"\\nLoss Data for Savings_WAP_6M:\")\n",
    "display(loss_wap_6m_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d849ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation matrix\n",
    "corr_matrix = Final_report.corr()\n",
    "\n",
    "# Create a correlation heatmap plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89773279",
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_report['Total_Value_in_Taka'].iplot(kind='bar', xTitle='claps',\n",
    "                  yTitle='count', title='Claps Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae64c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly           #(version 4.5.4) #pip install plotly==4.5.4\n",
    "import plotly.express as px\n",
    "import plotly.io as pio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ab2c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "barchart = px.bar(\n",
    "    data_frame=Final_report,\n",
    "    x=\"Business Name\",\n",
    "    y=\"Total_Value_in_Taka\",\n",
    "    color=\"Order Type\",               # differentiate color of marks\n",
    "    opacity=0.9,                  # set opacity of markers (from 0 to 1)\n",
    "    orientation=\"v\",              # 'v','h': orientation of the marks\n",
    "    barmode='relative',\n",
    "    #hover_name='under_trial',   # values appear in bold in the hover tooltip\n",
    "     hover_data=['Savings_WAP'],    # values appear as extra data in the hover tooltip\n",
    "    # custom_data=['others']\n",
    "\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cc81c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pio.show(barchart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5875df89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00df5e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f51c48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331f78cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b976ba34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "60673a04",
   "metadata": {},
   "source": [
    "#### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96523d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "# path = \n",
    "writer = pd.ExcelWriter(r'D:\\Shaikh_Desktop_Mydoc\\Desktop\\Automation Projects\\20230727_Savings_Report_Commercial\\Output_file\\sav_V04.xlsx', engine='xlsxwriter')\n",
    "\n",
    "\n",
    "# Write the MonthlyData DataFrame to a worksheet.\n",
    "\n",
    "Final_report.to_excel(writer, sheet_name='Top', index=False)\n",
    "df_report_.to_excel(writer, sheet_name='COM', index=False)\n",
    "high_variance_df_ANA2.to_excel(writer, sheet_name='COM_ANA', index=False)\n",
    "duplicate_rows.to_excel(writer, sheet_name='DuplicateData', index=False)\n",
    "\n",
    "\n",
    "\n",
    "# Save the writer and close it.\n",
    "writer.save()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4fe68e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
